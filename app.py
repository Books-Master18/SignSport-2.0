from flask import Flask, request, jsonify, render_template
import re
from sport_rules import SPORT_RULES
from config import PROJECT_PROGRESS
import pymorphy3
from synonyms import SYNONYM_GROUPS

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
morph = pymorphy3.MorphAnalyzer()

# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def normalize_phrase(phrase):
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–∑—É –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ª–µ–º–º."""
    words = re.findall(r'[–∞-—è—ë]+', phrase.lower())
    lemmas = set()
    for word in words:
        parsed = morph.parse(word)
        if parsed:
            lemma = parsed[0].normal_form
            lemmas.add(lemma)
    return lemmas

# === –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ ===
NORMALIZED_SYNONYMS = {}
for concept, phrases in SYNONYM_GROUPS.items():
    normalized_phrases = []
    for phrase in phrases:
        normalized_phrases.append(normalize_phrase(phrase))
    NORMALIZED_SYNONYMS[concept] = normalized_phrases

def is_meaningful_text(text):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂ –ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞."""
    if len(text) < 20:
        return False
    russian_words = re.findall(r'[–∞-—è—ë]{3,}', text.lower())
    return len(russian_words) >= 3

def lemmatize_text_to_set(text):
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ª–µ–º–º (–±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞)."""
    words = re.findall(r'[–∞-—è—ë]+', text.lower())
    lemmas = set()
    for word in words:
        parsed = morph.parse(word)
        if parsed:
            lemma = parsed[0].normal_form
            lemmas.add(lemma)
    return lemmas

def expand_text_with_synonyms(user_lemmas, normalized_synonyms):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ª–µ–º–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ—Ä–∞–∑–∞–º–∏."""
    matched_concepts = set()
    for concept, phrase_lemmas_list in normalized_synonyms.items():
        for phrase_lemmas in phrase_lemmas_list:
            if phrase_lemmas.issubset(user_lemmas):
                matched_concepts.add(concept)
                break
    return matched_concepts

# === –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ ===
def analyze_with_rules(text):
    if not is_meaningful_text(text):
        return {"error": "..."}

    user_lemmas = lemmatize_text_to_set(text)
    user_concepts = expand_text_with_synonyms(user_lemmas, NORMALIZED_SYNONYMS)

    # 1. –°—á–∏—Ç–∞–µ–º –±–∞–∑–æ–≤—ã–µ –±–∞–ª–ª—ã
    scores = {}
    for sport, rule in SPORT_RULES.items():
        total_weight = 0
        keywords = rule.get("keywords", {})
        for concept, weight in keywords.items():
            if concept in user_concepts:
                total_weight += weight
        scores[sport] = total_weight

    # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –ù–ï–ì–ê–¢–ò–í–ù–´–ï –ú–ê–†–ö–ï–†–´ (–¥–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏!)
    if "–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å_–≤_–æ–¥–æ–±—Ä–µ–Ω–∏–∏" in user_concepts:
        scores["–ü–ª–∞–≤–∞–Ω–∏–µüèä"] = max(0, scores.get("–ü–ª–∞–≤–∞–Ω–∏–µüèä", 0) - 15)

    # 3. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –±–∞–ª–ª–æ–≤
    sorted_sports = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    best_sport, best_score = sorted_sports[0]

    if best_score <= 0:
        return {
            "sport": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–ø–æ—Ä—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–ª–∞–≤–∞–Ω–∏–µ)",
            "confidence": 60,
            "reason": "–û–ø–∏—Å–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —è–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–∏–¥ —Å–ø–æ—Ä—Ç–∞.",
            "additional_recommendations": []
        }

    rule = SPORT_RULES[best_sport]
    max_possible = rule.get("max_score", sum(rule.get("keywords", {}).values()))
    confidence = min(95, max(50, int((best_score / max_possible) * 100)))
    reason = rule.get("reason", "")

    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
    alternatives = []
    for sport, score in sorted_sports[1:3]:
        if score > 0:
            alt_rule = SPORT_RULES[sport]
            alt_max = alt_rule.get("max_score", sum(alt_rule.get("keywords", {}).values()))
            alt_conf = min(90, max(40, int((score / alt_max) * 100))) if alt_max > 0 else 50
            alternatives.append({"sport": sport, "confidence": alt_conf})

    return {
        "sport": best_sport,
        "confidence": confidence,
        "reason": reason,
        "additional_recommendations": alternatives
    }

# === FLASK-–ü–†–ò–õ–û–ñ–ï–ù–ò–ï ===
app = Flask(__name__)

@app.context_processor
def inject_global_vars():
    return {'progress': PROJECT_PROGRESS}

@app.route('/')
def home():
    return render_template('Main_page.html')

@app.route('/analyze')
def analyze_page():
    return render_template('SignSport-2.0.html')

@app.route('/goodbye')
def goodbye():
    return render_template('goodbye.html')

@app.route('/api/analyze', methods=['POST'])
def analyze_text():
    data = request.get_json()
    if not data:
        return jsonify({"error": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö"}), 400

    text = data.get('text', '').strip()
    if not text:
        return jsonify({"error": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞."}), 400

    try:
        result = analyze_with_rules(text)
    except Exception as e:
        return jsonify({"error": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"}), 500

    if "error" in result:
        return jsonify(result), 400

    return jsonify(result)

@app.errorhandler(404)
def page_not_found(e):
    return "–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", 404

if __name__ == '__main__':
    print("\n" + "="*50)
    print("üöÄ –°–∞–π—Ç SignSport –∑–∞–ø—É—â–µ–Ω!")
    print("üëâ –ì–ª–∞–≤–Ω–∞—è: http://127.0.0.1:5000")
    print("="*50 + "\n")
    app.run(debug=True)